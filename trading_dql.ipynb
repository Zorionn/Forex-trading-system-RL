{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ForexTradingEnv(gym.Env):\n",
    "    def __init__(self, data, window_size=1000, initial_balance=1000, stop_loss_pct=0.02, take_profit_pct=0.05):\n",
    "        super(ForexTradingEnv, self).__init__()\n",
    "\n",
    "        self.data = data  # Forex price data, e.g., pandas DataFrame\n",
    "        self.initial_balance = initial_balance\n",
    "        self.window_size = window_size  # Number of past steps to include\n",
    "        self.stop_loss_pct = stop_loss_pct\n",
    "        self.take_profit_pct = take_profit_pct\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        self.balance = initial_balance\n",
    "        self.position = None  # 'long' or 'short'\n",
    "        self.entry_price = 0.0\n",
    "\n",
    "        # Define action and observation space\n",
    "        self.action_space = spaces.Discrete(3)  # Buy, Sell, Hold\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.window_size * 8,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.current_step = 0\n",
    "        self.position = None\n",
    "        self.entry_price = 0.0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "         # Check if we are within the initial steps where full `window_size` data isn't available\n",
    "        start_index = max(0, self.current_step - self.window_size)\n",
    "        window_data = self.data.iloc[start_index : self.current_step]\n",
    "\n",
    "        # If the current step is less than `window_size`, pad with zeros at the beginning\n",
    "        if len(window_data) < self.window_size:\n",
    "            # Number of missing rows to pad\n",
    "            padding_rows = self.window_size - len(window_data)\n",
    "            # Create padding of zeros (8 features per step)\n",
    "            padding = np.zeros((padding_rows, 8))\n",
    "            # Concatenate padding with available data\n",
    "            window_data = np.vstack((padding, window_data[['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close',\n",
    "                                                        'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']].values))\n",
    "        else:\n",
    "            # Otherwise, just get the required values without padding\n",
    "            window_data = window_data[['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close',\n",
    "                                    'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']].values\n",
    "\n",
    "        # Flatten the array to make it a 1D observation\n",
    "        observation = window_data.flatten()\n",
    "        return observation.astype(np.float32)\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        current_price = self.data.iloc[self.current_step]['Bid_Close']\n",
    "        reward = 0\n",
    "\n",
    "        if self.position is None:\n",
    "            # Only take Buy or Sell actions if there is no open position\n",
    "            if action == 1:  # Buy\n",
    "                self.position = 'long'\n",
    "                self.entry_price = current_price\n",
    "            elif action == 2:  # Sell\n",
    "                self.position = 'short'\n",
    "                self.entry_price = current_price\n",
    "            # No reward as we are just entering a position\n",
    "        else:\n",
    "            # Only check for stop loss or target if we have an open position\n",
    "            if self.position == 'long':\n",
    "                # Calculate potential profit/loss\n",
    "                profit_pct = (current_price - self.entry_price) / self.entry_price\n",
    "\n",
    "                # Check for stop-loss or take-profit\n",
    "                if profit_pct <= -self.stop_loss_pct:\n",
    "                    reward = current_price - self.entry_price  # Loss from stop-loss\n",
    "                    self.position = None  # Exit position\n",
    "                elif profit_pct >= self.take_profit_pct:\n",
    "                    reward = current_price - self.entry_price  # Profit from take-profit\n",
    "                    self.position = None  # Exit position\n",
    "\n",
    "            elif self.position == 'short':\n",
    "                # Calculate potential profit/loss\n",
    "                profit_pct = (self.entry_price - current_price) / self.entry_price\n",
    "\n",
    "                # Check for stop-loss or take-profit\n",
    "                if profit_pct <= -self.stop_loss_pct:\n",
    "                    reward = self.entry_price - current_price  # Loss from stop-loss\n",
    "                    self.position = None  # Exit position\n",
    "                elif profit_pct >= self.take_profit_pct:\n",
    "                    reward = self.entry_price - current_price  # Profit from take-profit\n",
    "                    self.position = None  # Exit position\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.position is not None and action in [1, 2]:\n",
    "            # Ignore Buy or Sell actions if we already have an open position\n",
    "            action = 0  # Force Hold action\n",
    "        reward = self._take_action(action)\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, action, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import copy\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_agent(env, num_episodes=5, gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995, batch_size=32):\n",
    "    memory = deque(maxlen=2000)\n",
    "    model = DQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        total_reward = 0.0\n",
    "        historic_state = state.clone()\n",
    "        historic_action = torch.argmax(model(state)).item()\n",
    "        for t in range(len(env.data)):\n",
    "            if random.random() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    action = torch.argmax(model(state)).item()\n",
    "\n",
    "            next_state, reward, done, action, _ = env.step(action)\n",
    "            if action != 0:\n",
    "                historic_state = state.clone()\n",
    "                historic_action = copy.copy(action)\n",
    "            next_state = torch.FloatTensor(next_state).unsqueeze(0).to(device)\n",
    "            if(reward != 0):\n",
    "                total_reward += reward\n",
    "                memory.append((historic_state, historic_action, reward, next_state, done))\n",
    "                print(f\"Episode {episode}, Step {t}, Action: {historic_action}, Reward: {reward:.4f}, Total Reward: {total_reward:.4f}\")\n",
    "            state = next_state\n",
    "            \n",
    "            \n",
    "            if done:\n",
    "                print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
    "                break\n",
    "\n",
    "            # Replay and update\n",
    "            if len(memory) >= batch_size:\n",
    "                batch = random.sample(memory, batch_size)\n",
    "                state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*batch)\n",
    "\n",
    "                state_batch = torch.cat([s for s in state_batch]).to(device)\n",
    "                action_batch = torch.tensor(action_batch, device=device)\n",
    "                reward_batch = torch.tensor(reward_batch, dtype=torch.float32, device=device)\n",
    "                next_state_batch = torch.cat([ns for ns in next_state_batch]).to(device)\n",
    "                done_batch = torch.tensor(done_batch, dtype=torch.float32, device=device)\n",
    "\n",
    "                current_q = model(state_batch).gather(1, action_batch.unsqueeze(1)).squeeze()\n",
    "                max_next_q = model(next_state_batch).max(1)[0]\n",
    "                expected_q = reward_batch + (1 - done_batch) * gamma * max_next_q\n",
    "\n",
    "                loss = criterion(current_q, expected_q.detach())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Step 962, Action: 2, Reward: 0.0809, Total Reward: 0.0809\n",
      "Episode 0, Step 2355, Action: 2, Reward: 0.0769, Total Reward: 0.1579\n",
      "Episode 0, Step 3004, Action: 2, Reward: -0.0301, Total Reward: 0.1278\n",
      "Episode 0, Step 3730, Action: 1, Reward: 0.0798, Total Reward: 0.2076\n",
      "Episode 0, Step 4273, Action: 1, Reward: -0.0314, Total Reward: 0.1762\n",
      "Episode 0, Step 4589, Action: 2, Reward: -0.0324, Total Reward: 0.1438\n",
      "Episode 0, Step 5063, Action: 2, Reward: -0.0314, Total Reward: 0.1124\n",
      "Episode 0, Step 5145, Action: 1, Reward: -0.0335, Total Reward: 0.0789\n",
      "Episode 0, Step 6297, Action: 1, Reward: -0.0338, Total Reward: 0.0451\n",
      "Episode 0, Step 6673, Action: 2, Reward: -0.0316, Total Reward: 0.0134\n",
      "Episode 0, Step 7051, Action: 2, Reward: -0.0315, Total Reward: -0.0181\n",
      "Episode 0, Step 11693, Action: 1, Reward: -0.0331, Total Reward: -0.0512\n",
      "Episode 0, Step 12580, Action: 2, Reward: -0.0318, Total Reward: -0.0830\n",
      "Episode 0, Step 13992, Action: 2, Reward: 0.0807, Total Reward: -0.0024\n",
      "Episode 0, Step 14137, Action: 2, Reward: -0.0309, Total Reward: -0.0333\n",
      "Episode 0, Step 14429, Action: 2, Reward: -0.0317, Total Reward: -0.0650\n",
      "Episode 0, Step 15858, Action: 2, Reward: -0.0332, Total Reward: -0.0982\n",
      "Episode 0, Step 16458, Action: 2, Reward: 0.0846, Total Reward: -0.0136\n",
      "Episode 0, Step 16739, Action: 2, Reward: -0.0327, Total Reward: -0.0463\n",
      "Episode 0, Step 18251, Action: 2, Reward: -0.0323, Total Reward: -0.0786\n",
      "Episode 0, Step 20160, Action: 2, Reward: -0.0333, Total Reward: -0.1118\n",
      "Episode 0, Step 20928, Action: 2, Reward: 0.0819, Total Reward: -0.0300\n",
      "Episode 0, Step 24516, Action: 2, Reward: -0.0312, Total Reward: -0.0612\n",
      "Episode 0, Step 26764, Action: 1, Reward: 0.0805, Total Reward: 0.0194\n",
      "Episode 0, Step 26947, Action: 1, Reward: -0.0336, Total Reward: -0.0142\n",
      "Episode 0, Step 27110, Action: 2, Reward: -0.0327, Total Reward: -0.0468\n",
      "Episode 0, Step 30634, Action: 1, Reward: -0.0431, Total Reward: -0.0899\n",
      "Episode 0, Step 32612, Action: 2, Reward: 0.0819, Total Reward: -0.0081\n",
      "Episode 0, Step 32685, Action: 1, Reward: -0.0325, Total Reward: -0.0405\n",
      "Episode 0, Step 33811, Action: 1, Reward: -0.0304, Total Reward: -0.0709\n",
      "Episode 0, Step 34606, Action: 1, Reward: 0.0760, Total Reward: 0.0051\n",
      "Episode 0, Step 34654, Action: 1, Reward: -0.0321, Total Reward: -0.0270\n",
      "Episode 0, Step 35462, Action: 1, Reward: 0.0771, Total Reward: 0.0501\n",
      "Episode 0, Step 35734, Action: 1, Reward: -0.0318, Total Reward: 0.0183\n",
      "Episode 0, Step 38755, Action: 2, Reward: 0.0780, Total Reward: 0.0963\n",
      "Episode 0, Step 39689, Action: 2, Reward: 0.0754, Total Reward: 0.1717\n",
      "Episode 0, Step 39999, Action: 2, Reward: -0.0314, Total Reward: 0.1403\n",
      "Episode 0, Step 40064, Action: 1, Reward: -0.0288, Total Reward: 0.1115\n",
      "Episode 0, Step 41771, Action: 1, Reward: 0.0729, Total Reward: 0.1844\n",
      "Episode 0, Step 41788, Action: 2, Reward: 0.1321, Total Reward: 0.3164\n",
      "Episode 0, Step 41966, Action: 1, Reward: -0.0320, Total Reward: 0.2844\n",
      "Episode 0, Step 42133, Action: 2, Reward: -0.0282, Total Reward: 0.2562\n",
      "Episode 0, Step 43574, Action: 2, Reward: 0.0690, Total Reward: 0.3253\n",
      "Episode 0, Step 47001, Action: 2, Reward: -0.0260, Total Reward: 0.2993\n",
      "Episode 0, Step 47917, Action: 1, Reward: -0.0282, Total Reward: 0.2711\n",
      "Episode 0, Step 49352, Action: 1, Reward: 0.0643, Total Reward: 0.3354\n",
      "Episode 0, Total Reward: 0.33541999999999894\n",
      "Episode 1, Step 591, Action: 1, Reward: -0.0326, Total Reward: -0.0326\n",
      "Episode 1, Step 855, Action: 1, Reward: -0.0355, Total Reward: -0.0681\n",
      "Episode 1, Step 1018, Action: 1, Reward: -0.0325, Total Reward: -0.1006\n",
      "Episode 1, Step 1753, Action: 2, Reward: -0.0318, Total Reward: -0.1324\n",
      "Episode 1, Step 2187, Action: 1, Reward: -0.0337, Total Reward: -0.1661\n",
      "Episode 1, Step 2380, Action: 2, Reward: 0.0773, Total Reward: -0.0887\n",
      "Episode 1, Step 2593, Action: 2, Reward: -0.0289, Total Reward: -0.1176\n",
      "Episode 1, Step 3452, Action: 1, Reward: 0.0741, Total Reward: -0.0435\n",
      "Episode 1, Step 3699, Action: 2, Reward: -0.0319, Total Reward: -0.0754\n",
      "Episode 1, Step 4397, Action: 1, Reward: -0.0314, Total Reward: -0.1068\n",
      "Episode 1, Step 4550, Action: 2, Reward: -0.0319, Total Reward: -0.1387\n",
      "Episode 1, Step 4943, Action: 2, Reward: -0.0363, Total Reward: -0.1750\n",
      "Episode 1, Step 5156, Action: 1, Reward: -0.0337, Total Reward: -0.2087\n",
      "Episode 1, Step 5350, Action: 2, Reward: -0.0320, Total Reward: -0.2407\n",
      "Episode 1, Step 5835, Action: 1, Reward: -0.0335, Total Reward: -0.2742\n",
      "Episode 1, Step 6299, Action: 1, Reward: -0.0316, Total Reward: -0.3057\n",
      "Episode 1, Step 6672, Action: 2, Reward: -0.0326, Total Reward: -0.3384\n",
      "Episode 1, Step 8686, Action: 1, Reward: 0.0798, Total Reward: -0.2586\n",
      "Episode 1, Step 9141, Action: 1, Reward: -0.0343, Total Reward: -0.2929\n",
      "Episode 1, Step 9491, Action: 2, Reward: -0.0346, Total Reward: -0.3275\n",
      "Episode 1, Step 11773, Action: 2, Reward: 0.0832, Total Reward: -0.2443\n",
      "Episode 1, Step 11858, Action: 1, Reward: -0.0370, Total Reward: -0.2813\n",
      "Episode 1, Step 11949, Action: 2, Reward: -0.0336, Total Reward: -0.3149\n",
      "Episode 1, Step 12497, Action: 2, Reward: -0.0318, Total Reward: -0.3467\n",
      "Episode 1, Step 13008, Action: 1, Reward: -0.0336, Total Reward: -0.3803\n",
      "Episode 1, Step 14813, Action: 2, Reward: -0.0318, Total Reward: -0.4121\n",
      "Episode 1, Step 15020, Action: 1, Reward: -0.0319, Total Reward: -0.4440\n",
      "Episode 1, Step 15270, Action: 2, Reward: -0.0313, Total Reward: -0.4753\n",
      "Episode 1, Step 16413, Action: 1, Reward: -0.0319, Total Reward: -0.5072\n",
      "Episode 1, Step 18195, Action: 2, Reward: -0.0333, Total Reward: -0.5405\n",
      "Episode 1, Step 18444, Action: 2, Reward: -0.0332, Total Reward: -0.5736\n",
      "Episode 1, Step 18998, Action: 1, Reward: -0.0334, Total Reward: -0.6071\n",
      "Episode 1, Step 20878, Action: 1, Reward: -0.0331, Total Reward: -0.6402\n",
      "Episode 1, Step 24568, Action: 2, Reward: -0.0359, Total Reward: -0.6761\n",
      "Episode 1, Step 27151, Action: 1, Reward: 0.0797, Total Reward: -0.5964\n",
      "Episode 1, Step 30603, Action: 1, Reward: -0.0345, Total Reward: -0.6309\n",
      "Episode 1, Step 31106, Action: 1, Reward: -0.0372, Total Reward: -0.6681\n",
      "Episode 1, Step 31825, Action: 1, Reward: -0.0332, Total Reward: -0.7012\n",
      "Episode 1, Step 33792, Action: 2, Reward: 0.0786, Total Reward: -0.6226\n",
      "Episode 1, Step 34800, Action: 1, Reward: 0.0746, Total Reward: -0.5481\n",
      "Episode 1, Step 35106, Action: 1, Reward: -0.0313, Total Reward: -0.5794\n",
      "Episode 1, Step 38325, Action: 1, Reward: -0.0316, Total Reward: -0.6110\n",
      "Episode 1, Step 38864, Action: 1, Reward: -0.0299, Total Reward: -0.6409\n",
      "Episode 1, Step 39707, Action: 2, Reward: 0.0735, Total Reward: -0.5674\n",
      "Episode 1, Step 39859, Action: 2, Reward: -0.0282, Total Reward: -0.5956\n",
      "Episode 1, Step 40095, Action: 2, Reward: -0.0301, Total Reward: -0.6258\n",
      "Episode 1, Step 40182, Action: 1, Reward: -0.0291, Total Reward: -0.6549\n",
      "Episode 1, Step 40741, Action: 2, Reward: -0.0316, Total Reward: -0.6865\n",
      "Episode 1, Step 41569, Action: 1, Reward: -0.0294, Total Reward: -0.7158\n",
      "Episode 1, Step 41689, Action: 2, Reward: -0.0363, Total Reward: -0.7521\n",
      "Episode 1, Step 41788, Action: 1, Reward: -0.1005, Total Reward: -0.8526\n",
      "Episode 1, Step 41793, Action: 2, Reward: -0.0365, Total Reward: -0.8891\n",
      "Episode 1, Step 41820, Action: 2, Reward: 0.0696, Total Reward: -0.8194\n",
      "Episode 1, Step 41979, Action: 1, Reward: -0.0277, Total Reward: -0.8471\n",
      "Episode 1, Step 43580, Action: 1, Reward: -0.0270, Total Reward: -0.8742\n",
      "Episode 1, Step 43595, Action: 1, Reward: -0.0300, Total Reward: -0.9042\n",
      "Episode 1, Step 44194, Action: 2, Reward: -0.0272, Total Reward: -0.9313\n",
      "Episode 1, Step 46999, Action: 2, Reward: -0.0256, Total Reward: -0.9569\n",
      "Episode 1, Step 47917, Action: 1, Reward: -0.0270, Total Reward: -0.9839\n",
      "Episode 1, Step 48680, Action: 1, Reward: 0.0634, Total Reward: -0.9204\n",
      "Episode 1, Step 48876, Action: 1, Reward: -0.0267, Total Reward: -0.9471\n",
      "Episode 1, Step 49424, Action: 1, Reward: 0.0671, Total Reward: -0.8800\n",
      "Episode 1, Step 49689, Action: 1, Reward: -0.0278, Total Reward: -0.9078\n",
      "Episode 1, Total Reward: -0.9078399999999993\n",
      "Episode 2, Step 962, Action: 2, Reward: 0.0809, Total Reward: 0.0809\n",
      "Episode 2, Step 1022, Action: 1, Reward: -0.0356, Total Reward: 0.0453\n",
      "Episode 2, Step 1139, Action: 2, Reward: -0.0303, Total Reward: 0.0151\n",
      "Episode 2, Step 1474, Action: 1, Reward: -0.0344, Total Reward: -0.0194\n",
      "Episode 2, Step 2359, Action: 1, Reward: -0.0312, Total Reward: -0.0506\n",
      "Episode 2, Step 3003, Action: 2, Reward: -0.0300, Total Reward: -0.0806\n",
      "Episode 2, Step 3680, Action: 1, Reward: 0.0758, Total Reward: -0.0048\n",
      "Episode 2, Step 3774, Action: 2, Reward: -0.0322, Total Reward: -0.0370\n",
      "Episode 2, Step 5442, Action: 2, Reward: -0.0363, Total Reward: -0.0732\n",
      "Episode 2, Step 5646, Action: 1, Reward: -0.0388, Total Reward: -0.1120\n",
      "Episode 2, Step 5872, Action: 1, Reward: -0.0328, Total Reward: -0.1447\n",
      "Episode 2, Step 6125, Action: 2, Reward: -0.0325, Total Reward: -0.1772\n",
      "Episode 2, Step 6176, Action: 1, Reward: -0.0341, Total Reward: -0.2113\n",
      "Episode 2, Step 6697, Action: 2, Reward: -0.0324, Total Reward: -0.2438\n",
      "Episode 2, Step 7083, Action: 2, Reward: -0.0324, Total Reward: -0.2762\n",
      "Episode 2, Step 8687, Action: 2, Reward: -0.0344, Total Reward: -0.3106\n",
      "Episode 2, Step 11771, Action: 2, Reward: 0.0838, Total Reward: -0.2267\n",
      "Episode 2, Step 12546, Action: 2, Reward: -0.0318, Total Reward: -0.2586\n",
      "Episode 2, Step 12941, Action: 1, Reward: -0.0326, Total Reward: -0.2911\n",
      "Episode 2, Step 13703, Action: 1, Reward: -0.0330, Total Reward: -0.3241\n",
      "Episode 2, Step 15816, Action: 1, Reward: 0.0773, Total Reward: -0.2467\n",
      "Episode 2, Step 16204, Action: 1, Reward: -0.0327, Total Reward: -0.2794\n",
      "Episode 2, Step 18307, Action: 2, Reward: -0.0330, Total Reward: -0.3124\n",
      "Episode 2, Step 21024, Action: 2, Reward: 0.0826, Total Reward: -0.2298\n",
      "Episode 2, Step 22860, Action: 2, Reward: -0.0310, Total Reward: -0.2608\n",
      "Episode 2, Step 23212, Action: 1, Reward: -0.0329, Total Reward: -0.2937\n",
      "Episode 2, Step 24052, Action: 2, Reward: -0.0316, Total Reward: -0.3253\n",
      "Episode 2, Step 24568, Action: 2, Reward: -0.0366, Total Reward: -0.3619\n",
      "Episode 2, Step 27151, Action: 1, Reward: 0.0797, Total Reward: -0.2821\n",
      "Episode 2, Step 29451, Action: 2, Reward: -0.0355, Total Reward: -0.3176\n",
      "Episode 2, Step 30214, Action: 1, Reward: -0.0369, Total Reward: -0.3545\n",
      "Episode 2, Step 31684, Action: 2, Reward: 0.0853, Total Reward: -0.2692\n",
      "Episode 2, Step 32702, Action: 2, Reward: 0.0803, Total Reward: -0.1889\n",
      "Episode 2, Step 33306, Action: 2, Reward: -0.0315, Total Reward: -0.2204\n",
      "Episode 2, Step 34308, Action: 2, Reward: 0.0779, Total Reward: -0.1425\n",
      "Episode 2, Step 34585, Action: 1, Reward: 0.0739, Total Reward: -0.0687\n",
      "Episode 2, Step 34815, Action: 2, Reward: -0.0309, Total Reward: -0.0996\n",
      "Episode 2, Step 35060, Action: 1, Reward: -0.0316, Total Reward: -0.1312\n",
      "Episode 2, Step 37892, Action: 1, Reward: -0.0338, Total Reward: -0.1650\n",
      "Episode 2, Step 38803, Action: 1, Reward: -0.0326, Total Reward: -0.1976\n",
      "Episode 2, Step 38963, Action: 1, Reward: -0.0303, Total Reward: -0.2279\n",
      "Episode 2, Step 39099, Action: 1, Reward: -0.0290, Total Reward: -0.2569\n",
      "Episode 2, Step 39760, Action: 1, Reward: -0.0291, Total Reward: -0.2859\n",
      "Episode 2, Step 40762, Action: 1, Reward: 0.0706, Total Reward: -0.2154\n",
      "Episode 2, Step 41772, Action: 2, Reward: -0.0334, Total Reward: -0.2487\n",
      "Episode 2, Step 41785, Action: 1, Reward: -0.0344, Total Reward: -0.2831\n",
      "Episode 2, Step 41788, Action: 2, Reward: 0.0831, Total Reward: -0.2000\n",
      "Episode 2, Step 41966, Action: 1, Reward: -0.0320, Total Reward: -0.2321\n",
      "Episode 2, Step 42133, Action: 2, Reward: -0.0282, Total Reward: -0.2602\n",
      "Episode 2, Step 43574, Action: 2, Reward: 0.0690, Total Reward: -0.1912\n",
      "Episode 2, Step 43585, Action: 1, Reward: -0.0256, Total Reward: -0.2168\n",
      "Episode 2, Step 44534, Action: 2, Reward: -0.0258, Total Reward: -0.2425\n",
      "Episode 2, Step 44843, Action: 1, Reward: -0.0253, Total Reward: -0.2678\n",
      "Episode 2, Step 45422, Action: 2, Reward: -0.0257, Total Reward: -0.2935\n",
      "Episode 2, Step 46011, Action: 1, Reward: -0.0253, Total Reward: -0.3188\n",
      "Episode 2, Step 47360, Action: 1, Reward: 0.0648, Total Reward: -0.2539\n",
      "Episode 2, Step 47733, Action: 1, Reward: -0.0298, Total Reward: -0.2837\n",
      "Episode 2, Step 49424, Action: 1, Reward: 0.0729, Total Reward: -0.2108\n",
      "Episode 2, Step 49689, Action: 1, Reward: -0.0278, Total Reward: -0.2386\n",
      "Episode 2, Total Reward: -0.23857000000000106\n",
      "Episode 3, Step 591, Action: 1, Reward: -0.0335, Total Reward: -0.0335\n",
      "Episode 3, Step 1022, Action: 2, Reward: 0.0868, Total Reward: 0.0533\n",
      "Episode 3, Step 2232, Action: 1, Reward: -0.0303, Total Reward: 0.0230\n",
      "Episode 3, Step 2380, Action: 1, Reward: -0.0359, Total Reward: -0.0129\n",
      "Episode 3, Step 2593, Action: 2, Reward: -0.0289, Total Reward: -0.0418\n",
      "Episode 3, Step 3452, Action: 1, Reward: 0.0741, Total Reward: 0.0324\n",
      "Episode 3, Step 3729, Action: 2, Reward: -0.0307, Total Reward: 0.0016\n",
      "Episode 3, Step 5063, Action: 2, Reward: -0.0334, Total Reward: -0.0317\n",
      "Episode 3, Step 8060, Action: 2, Reward: -0.0325, Total Reward: -0.0642\n",
      "Episode 3, Step 8826, Action: 2, Reward: -0.0368, Total Reward: -0.1009\n",
      "Episode 3, Step 10367, Action: 2, Reward: 0.0846, Total Reward: -0.0164\n",
      "Episode 3, Step 11841, Action: 1, Reward: -0.0351, Total Reward: -0.0514\n",
      "Episode 3, Step 12313, Action: 2, Reward: -0.0329, Total Reward: -0.0843\n",
      "Episode 3, Step 13090, Action: 1, Reward: -0.0322, Total Reward: -0.1165\n",
      "Episode 3, Step 14282, Action: 2, Reward: -0.0321, Total Reward: -0.1487\n",
      "Episode 3, Step 15729, Action: 2, Reward: -0.0318, Total Reward: -0.1805\n",
      "Episode 3, Step 16476, Action: 2, Reward: 0.0810, Total Reward: -0.0995\n",
      "Episode 3, Step 18271, Action: 1, Reward: 0.0769, Total Reward: -0.0226\n",
      "Episode 3, Step 20565, Action: 1, Reward: -0.0344, Total Reward: -0.0570\n",
      "Episode 3, Step 21006, Action: 1, Reward: -0.0326, Total Reward: -0.0896\n",
      "Episode 3, Step 23025, Action: 2, Reward: -0.0319, Total Reward: -0.1215\n",
      "Episode 3, Step 23360, Action: 2, Reward: 0.0810, Total Reward: -0.0405\n",
      "Episode 3, Step 23442, Action: 2, Reward: -0.0302, Total Reward: -0.0707\n",
      "Episode 3, Step 23909, Action: 2, Reward: -0.0321, Total Reward: -0.1028\n",
      "Episode 3, Step 24839, Action: 1, Reward: 0.0784, Total Reward: -0.0244\n",
      "Episode 3, Step 25115, Action: 1, Reward: -0.0336, Total Reward: -0.0580\n",
      "Episode 3, Step 25828, Action: 2, Reward: -0.0331, Total Reward: -0.0910\n",
      "Episode 3, Step 26780, Action: 2, Reward: -0.0331, Total Reward: -0.1241\n",
      "Episode 3, Step 26945, Action: 1, Reward: -0.0345, Total Reward: -0.1586\n",
      "Episode 3, Step 29451, Action: 1, Reward: 0.0822, Total Reward: -0.0764\n",
      "Episode 3, Step 30634, Action: 2, Reward: 0.0918, Total Reward: 0.0154\n",
      "Episode 3, Step 32612, Action: 2, Reward: 0.0819, Total Reward: 0.0973\n",
      "Episode 3, Step 34290, Action: 2, Reward: 0.0778, Total Reward: 0.1752\n",
      "Episode 3, Step 34598, Action: 1, Reward: 0.0736, Total Reward: 0.2488\n",
      "Episode 3, Step 34823, Action: 2, Reward: -0.0312, Total Reward: 0.2176\n",
      "Episode 3, Step 38590, Action: 2, Reward: 0.0798, Total Reward: 0.2973\n",
      "Episode 3, Step 39132, Action: 2, Reward: 0.0755, Total Reward: 0.3729\n",
      "Episode 3, Step 41771, Action: 1, Reward: 0.0734, Total Reward: 0.4463\n",
      "Episode 3, Step 41785, Action: 1, Reward: -0.0335, Total Reward: 0.4128\n",
      "Episode 3, Step 41788, Action: 2, Reward: 0.0945, Total Reward: 0.5073\n",
      "Episode 3, Step 41821, Action: 1, Reward: -0.0280, Total Reward: 0.4792\n",
      "Episode 3, Step 41870, Action: 2, Reward: -0.0271, Total Reward: 0.4521\n",
      "Episode 3, Step 41897, Action: 1, Reward: -0.0278, Total Reward: 0.4243\n",
      "Episode 3, Step 41977, Action: 1, Reward: -0.0273, Total Reward: 0.3971\n",
      "Episode 3, Step 42082, Action: 2, Reward: -0.0266, Total Reward: 0.3704\n",
      "Episode 3, Step 42149, Action: 2, Reward: -0.0275, Total Reward: 0.3429\n",
      "Episode 3, Step 43523, Action: 2, Reward: 0.0672, Total Reward: 0.4101\n",
      "Episode 3, Step 43651, Action: 2, Reward: 0.0650, Total Reward: 0.4751\n",
      "Episode 3, Step 44566, Action: 1, Reward: 0.0606, Total Reward: 0.5357\n",
      "Episode 3, Step 46999, Action: 2, Reward: -0.0262, Total Reward: 0.5095\n",
      "Episode 3, Step 47917, Action: 1, Reward: -0.0282, Total Reward: 0.4813\n",
      "Episode 3, Step 48680, Action: 1, Reward: 0.0634, Total Reward: 0.5448\n",
      "Episode 3, Step 49424, Action: 2, Reward: -0.0297, Total Reward: 0.5151\n",
      "Episode 3, Total Reward: 0.5151000000000006\n",
      "Episode 4, Step 591, Action: 1, Reward: -0.0335, Total Reward: -0.0335\n",
      "Episode 4, Step 1022, Action: 2, Reward: 0.0883, Total Reward: 0.0548\n",
      "Episode 4, Step 2355, Action: 1, Reward: -0.0311, Total Reward: 0.0236\n",
      "Episode 4, Step 2978, Action: 2, Reward: -0.0312, Total Reward: -0.0076\n",
      "Episode 4, Step 3215, Action: 2, Reward: -0.0306, Total Reward: -0.0382\n",
      "Episode 4, Step 3625, Action: 2, Reward: -0.0314, Total Reward: -0.0696\n",
      "Episode 4, Step 5442, Action: 1, Reward: 0.0788, Total Reward: 0.0092\n",
      "Episode 4, Step 6220, Action: 2, Reward: 0.0820, Total Reward: 0.0912\n",
      "Episode 4, Step 6694, Action: 2, Reward: -0.0350, Total Reward: 0.0562\n",
      "Episode 4, Step 7083, Action: 2, Reward: -0.0333, Total Reward: 0.0229\n",
      "Episode 4, Step 10367, Action: 1, Reward: -0.0330, Total Reward: -0.0101\n",
      "Episode 4, Step 10560, Action: 2, Reward: -0.0373, Total Reward: -0.0474\n",
      "Episode 4, Step 11533, Action: 1, Reward: -0.0348, Total Reward: -0.0822\n",
      "Episode 4, Step 15863, Action: 2, Reward: -0.0325, Total Reward: -0.1147\n",
      "Episode 4, Step 16178, Action: 1, Reward: -0.0363, Total Reward: -0.1510\n",
      "Episode 4, Step 16427, Action: 1, Reward: -0.0337, Total Reward: -0.1847\n",
      "Episode 4, Step 20160, Action: 1, Reward: 0.0780, Total Reward: -0.1067\n",
      "Episode 4, Step 20918, Action: 2, Reward: 0.0822, Total Reward: -0.0246\n",
      "Episode 4, Step 24559, Action: 2, Reward: -0.0334, Total Reward: -0.0580\n",
      "Episode 4, Step 26780, Action: 1, Reward: 0.0798, Total Reward: 0.0218\n",
      "Episode 4, Step 26945, Action: 1, Reward: -0.0337, Total Reward: -0.0120\n",
      "Episode 4, Step 27111, Action: 2, Reward: -0.0328, Total Reward: -0.0447\n",
      "Episode 4, Step 28511, Action: 2, Reward: -0.0344, Total Reward: -0.0791\n",
      "Episode 4, Step 30309, Action: 1, Reward: -0.0343, Total Reward: -0.1134\n",
      "Episode 4, Step 30610, Action: 1, Reward: -0.0334, Total Reward: -0.1468\n",
      "Episode 4, Step 31106, Action: 1, Reward: -0.0343, Total Reward: -0.1812\n",
      "Episode 4, Step 32665, Action: 2, Reward: 0.0798, Total Reward: -0.1013\n",
      "Episode 4, Step 33416, Action: 2, Reward: -0.0303, Total Reward: -0.1317\n",
      "Episode 4, Step 33882, Action: 2, Reward: 0.0808, Total Reward: -0.0508\n",
      "Episode 4, Step 33890, Action: 2, Reward: -0.0310, Total Reward: -0.0818\n",
      "Episode 4, Step 34577, Action: 2, Reward: -0.0312, Total Reward: -0.1130\n",
      "Episode 4, Step 34800, Action: 2, Reward: -0.0308, Total Reward: -0.1439\n",
      "Episode 4, Step 35464, Action: 2, Reward: -0.0328, Total Reward: -0.1766\n",
      "Episode 4, Step 37892, Action: 2, Reward: 0.0858, Total Reward: -0.0908\n",
      "Episode 4, Step 38803, Action: 1, Reward: -0.0326, Total Reward: -0.1234\n",
      "Episode 4, Step 39696, Action: 2, Reward: 0.0739, Total Reward: -0.0495\n",
      "Episode 4, Step 39906, Action: 2, Reward: -0.0290, Total Reward: -0.0785\n",
      "Episode 4, Step 40762, Action: 2, Reward: -0.0306, Total Reward: -0.1091\n",
      "Episode 4, Step 41563, Action: 1, Reward: -0.0299, Total Reward: -0.1390\n",
      "Episode 4, Step 41783, Action: 1, Reward: 0.0745, Total Reward: -0.0645\n",
      "Episode 4, Step 41785, Action: 1, Reward: -0.0322, Total Reward: -0.0967\n",
      "Episode 4, Step 41793, Action: 2, Reward: -0.0365, Total Reward: -0.1331\n",
      "Episode 4, Step 41807, Action: 1, Reward: -0.0286, Total Reward: -0.1618\n",
      "Episode 4, Step 43520, Action: 2, Reward: 0.0688, Total Reward: -0.0930\n",
      "Episode 4, Step 43585, Action: 1, Reward: -0.0387, Total Reward: -0.1317\n",
      "Episode 4, Step 43651, Action: 1, Reward: -0.0282, Total Reward: -0.1598\n",
      "Episode 4, Step 44595, Action: 1, Reward: 0.0609, Total Reward: -0.0989\n",
      "Episode 4, Step 45181, Action: 2, Reward: 0.0638, Total Reward: -0.0351\n",
      "Episode 4, Step 45277, Action: 2, Reward: -0.0273, Total Reward: -0.0625\n",
      "Episode 4, Step 45427, Action: 2, Reward: -0.0252, Total Reward: -0.0877\n",
      "Episode 4, Step 45631, Action: 1, Reward: -0.0260, Total Reward: -0.1137\n",
      "Episode 4, Step 47157, Action: 1, Reward: 0.0618, Total Reward: -0.0519\n",
      "Episode 4, Step 47741, Action: 1, Reward: -0.0268, Total Reward: -0.0787\n",
      "Episode 4, Step 48079, Action: 2, Reward: -0.0260, Total Reward: -0.1046\n",
      "Episode 4, Step 48632, Action: 2, Reward: -0.0266, Total Reward: -0.1313\n",
      "Episode 4, Step 48870, Action: 1, Reward: -0.0265, Total Reward: -0.1578\n",
      "Episode 4, Step 49306, Action: 2, Reward: -0.0259, Total Reward: -0.1837\n",
      "Episode 4, Step 49424, Action: 2, Reward: -0.0331, Total Reward: -0.2168\n",
      "Episode 4, Step 49689, Action: 1, Reward: -0.0278, Total Reward: -0.2446\n",
      "Episode 4, Step 49789, Action: 1, Reward: -0.0277, Total Reward: -0.2723\n",
      "Episode 4, Step 49904, Action: 2, Reward: -0.0263, Total Reward: -0.2985\n",
      "Episode 4, Total Reward: -0.2985300000000004\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"HistoricData\\GBP_USD_2010_2017_hourly_bid_ask.csv\")\n",
    "env = ForexTradingEnv(data)\n",
    "model = train_agent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Bid_Open</th>\n",
       "      <th>Bid_Low</th>\n",
       "      <th>Bid_High</th>\n",
       "      <th>Bid_Close</th>\n",
       "      <th>Ask_Open</th>\n",
       "      <th>Ask_Low</th>\n",
       "      <th>Ask_High</th>\n",
       "      <th>Ask_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03T18:00:00.000000000Z</td>\n",
       "      <td>1.61542</td>\n",
       "      <td>1.61464</td>\n",
       "      <td>1.61635</td>\n",
       "      <td>1.61511</td>\n",
       "      <td>1.61642</td>\n",
       "      <td>1.61564</td>\n",
       "      <td>1.61735</td>\n",
       "      <td>1.61611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-03T19:00:00.000000000Z</td>\n",
       "      <td>1.61500</td>\n",
       "      <td>1.61390</td>\n",
       "      <td>1.61588</td>\n",
       "      <td>1.61488</td>\n",
       "      <td>1.61600</td>\n",
       "      <td>1.61490</td>\n",
       "      <td>1.61688</td>\n",
       "      <td>1.61588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03T20:00:00.000000000Z</td>\n",
       "      <td>1.61485</td>\n",
       "      <td>1.61422</td>\n",
       "      <td>1.61488</td>\n",
       "      <td>1.61426</td>\n",
       "      <td>1.61585</td>\n",
       "      <td>1.61522</td>\n",
       "      <td>1.61588</td>\n",
       "      <td>1.61526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-03T21:00:00.000000000Z</td>\n",
       "      <td>1.61426</td>\n",
       "      <td>1.61024</td>\n",
       "      <td>1.61426</td>\n",
       "      <td>1.61082</td>\n",
       "      <td>1.61526</td>\n",
       "      <td>1.61122</td>\n",
       "      <td>1.61562</td>\n",
       "      <td>1.61162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-03T22:00:00.000000000Z</td>\n",
       "      <td>1.61075</td>\n",
       "      <td>1.61051</td>\n",
       "      <td>1.61334</td>\n",
       "      <td>1.61237</td>\n",
       "      <td>1.61155</td>\n",
       "      <td>1.61128</td>\n",
       "      <td>1.61394</td>\n",
       "      <td>1.61297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51210</th>\n",
       "      <td>2017-12-29T17:00:00.000000000Z</td>\n",
       "      <td>1.35270</td>\n",
       "      <td>1.35215</td>\n",
       "      <td>1.35354</td>\n",
       "      <td>1.35231</td>\n",
       "      <td>1.35286</td>\n",
       "      <td>1.35233</td>\n",
       "      <td>1.35371</td>\n",
       "      <td>1.35250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51211</th>\n",
       "      <td>2017-12-29T18:00:00.000000000Z</td>\n",
       "      <td>1.35231</td>\n",
       "      <td>1.35170</td>\n",
       "      <td>1.35245</td>\n",
       "      <td>1.35238</td>\n",
       "      <td>1.35253</td>\n",
       "      <td>1.35191</td>\n",
       "      <td>1.35265</td>\n",
       "      <td>1.35258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51212</th>\n",
       "      <td>2017-12-29T19:00:00.000000000Z</td>\n",
       "      <td>1.35230</td>\n",
       "      <td>1.35147</td>\n",
       "      <td>1.35239</td>\n",
       "      <td>1.35169</td>\n",
       "      <td>1.35251</td>\n",
       "      <td>1.35169</td>\n",
       "      <td>1.35258</td>\n",
       "      <td>1.35187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51213</th>\n",
       "      <td>2017-12-29T20:00:00.000000000Z</td>\n",
       "      <td>1.35168</td>\n",
       "      <td>1.34997</td>\n",
       "      <td>1.35172</td>\n",
       "      <td>1.35000</td>\n",
       "      <td>1.35187</td>\n",
       "      <td>1.35018</td>\n",
       "      <td>1.35191</td>\n",
       "      <td>1.35020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51214</th>\n",
       "      <td>2017-12-29T21:00:00.000000000Z</td>\n",
       "      <td>1.35001</td>\n",
       "      <td>1.34926</td>\n",
       "      <td>1.35067</td>\n",
       "      <td>1.35000</td>\n",
       "      <td>1.35022</td>\n",
       "      <td>1.34965</td>\n",
       "      <td>1.35157</td>\n",
       "      <td>1.35090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51215 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Time  Bid_Open  Bid_Low  Bid_High  Bid_Close  \\\n",
       "0      2010-01-03T18:00:00.000000000Z   1.61542  1.61464   1.61635    1.61511   \n",
       "1      2010-01-03T19:00:00.000000000Z   1.61500  1.61390   1.61588    1.61488   \n",
       "2      2010-01-03T20:00:00.000000000Z   1.61485  1.61422   1.61488    1.61426   \n",
       "3      2010-01-03T21:00:00.000000000Z   1.61426  1.61024   1.61426    1.61082   \n",
       "4      2010-01-03T22:00:00.000000000Z   1.61075  1.61051   1.61334    1.61237   \n",
       "...                               ...       ...      ...       ...        ...   \n",
       "51210  2017-12-29T17:00:00.000000000Z   1.35270  1.35215   1.35354    1.35231   \n",
       "51211  2017-12-29T18:00:00.000000000Z   1.35231  1.35170   1.35245    1.35238   \n",
       "51212  2017-12-29T19:00:00.000000000Z   1.35230  1.35147   1.35239    1.35169   \n",
       "51213  2017-12-29T20:00:00.000000000Z   1.35168  1.34997   1.35172    1.35000   \n",
       "51214  2017-12-29T21:00:00.000000000Z   1.35001  1.34926   1.35067    1.35000   \n",
       "\n",
       "       Ask_Open  Ask_Low  Ask_High  Ask_Close  \n",
       "0       1.61642  1.61564   1.61735    1.61611  \n",
       "1       1.61600  1.61490   1.61688    1.61588  \n",
       "2       1.61585  1.61522   1.61588    1.61526  \n",
       "3       1.61526  1.61122   1.61562    1.61162  \n",
       "4       1.61155  1.61128   1.61394    1.61297  \n",
       "...         ...      ...       ...        ...  \n",
       "51210   1.35286  1.35233   1.35371    1.35250  \n",
       "51211   1.35253  1.35191   1.35265    1.35258  \n",
       "51212   1.35251  1.35169   1.35258    1.35187  \n",
       "51213   1.35187  1.35018   1.35191    1.35020  \n",
       "51214   1.35022  1.34965   1.35157    1.35090  \n",
       "\n",
       "[51215 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ForexTradingEnv at 0x254736c3130>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
